{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHevN8r0iJX8bQrwctP5um",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GHes31415/DeepBSDE/blob/master/grad_desc_wass_bary_gauss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5KuIyamuycJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I'm going to try the followin loss funciton for finding the barycenter of Gaussian distributions in the case $n = 2$\n"
      ],
      "metadata": {
        "id": "DBq8i3MPvLE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 2\n",
        "sig_1 = torch.tensor([[4,2],[2,3]],dtype= torch.float32)#.to(device)\n",
        "sig_2 = torch.tensor([[3,-1],[-1,5]],dtype= torch.float32)#.to(device)\n",
        "cov_mats = [sig_1,sig_2]\n",
        "k = torch.tensor(2)#.to(device)"
      ],
      "metadata": {
        "id": "uNKfhzGWu3Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for commutativity\n",
        "torch.norm(sig_1@sig_2-sig_2@sig_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7g8urrPxTp6",
        "outputId": "fc215821-b673-41e1-8fd7-d6bc484a3023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.2426)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sqrt_cov(sig: torch.tensor):\n",
        "  '''\n",
        "  sig: nxn SPD matrix\n",
        "  '''\n",
        "  D,U = torch.linalg.eig(sig)\n",
        "  return torch.matmul(torch.matmul(U,torch.diag(D**0.5)),torch.linalg.inv(U)).type(torch.float32)"
      ],
      "metadata": {
        "id": "ry-hdkZ5yNX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(theta,cov_mats,k):\n",
        "  '''\n",
        "  theta:    torch.tensor size n^2,\n",
        "            current estimate.\n",
        "  cov_mats: list of size k of tensors with shape nxn,\n",
        "            covariance matrices.\n",
        "  k:        torch.tensor size 1,\n",
        "            number of covariance matrices.\n",
        "  '''\n",
        "  theta_m = theta.reshape((n,n))#.to(device)\n",
        "  sig_theta = torch.matmul(theta_m,theta_m)\n",
        "  sig_theta_sqrt = sqrt_cov(sig_theta)\n",
        "  sig_theta_sqrt_inv = torch.linalg.inv(sig_theta_sqrt)\n",
        "  sum_loss = torch.tensor(0)#.to(device)\n",
        "  for sig in cov_mats:\n",
        "    first_mat = torch.matmul(torch.matmul(sig_theta_sqrt,sig),sig_theta_sqrt)\n",
        "    sqrt_mat = sqrt_cov(first_mat)\n",
        "    second_mat = torch.matmul(sig_theta_sqrt_inv,sqrt_mat)\n",
        "    sum_loss = sum_loss + torch.norm(sig_theta_sqrt-second_mat)\n",
        "  return sum_loss/k"
      ],
      "metadata": {
        "id": "cvV1-5o1v3-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_to_covs(theta,cov_mats,k):\n",
        "  '''\n",
        "  theta:    torch.tensor size n^2,\n",
        "            current estimate.\n",
        "  cov_mats: list of size k of tensors with shape nxn,\n",
        "            covariance matrices.\n",
        "  k:        torch.tensor size 1,\n",
        "            number of covariance matrices.\n",
        "  '''\n",
        "  theta_m = theta.reshape((n,n))#.to(device)\n",
        "  sig_theta = torch.matmul(theta_m,theta_m)\n",
        "  sig_theta_sqrt = sqrt_cov(sig_theta)\n",
        "  sig_theta_sqrt_inv = torch.linalg.inv(sig_theta_sqrt)\n",
        "  distances = []\n",
        "  for sig in cov_mats:\n",
        "    first_mat = torch.matmul(torch.matmul(sig_theta_sqrt,sig),sig_theta_sqrt)\n",
        "    sqrt_mat = sqrt_cov(first_mat)\n",
        "    second_mat = torch.matmul(sig_theta_sqrt_inv,sqrt_mat)\n",
        "    distances.append(torch.norm(sig_theta_sqrt-second_mat))\n",
        "  return distances\n"
      ],
      "metadata": {
        "id": "ZtQ4HZ4S7LgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = torch.tensor(0.1)#.to(device)\n",
        "n_iters = 100000\n",
        "theta = torch.rand(n**2,requires_grad=True)#.to(device)\n",
        "optimizer = torch.optim.Adam([theta],lr = 0.0001)"
      ],
      "metadata": {
        "id": "o_kAmRpp0gl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(n_iters):\n",
        "\n",
        "  # compute loss and backpropagate\n",
        "  l = loss(theta,cov_mats,k)\n",
        "  # if l<10**(-3):\n",
        "  #   continue\n",
        "  l.backward()\n",
        "  d_theta = theta.grad\n",
        "  # print(d_theta)\n",
        "  # update theta gradient descent\n",
        "  # with torch.no_grad():\n",
        "  #   theta -= lr*d_theta\n",
        "  optimizer.step()\n",
        "  # zero graidents\n",
        "  theta.grad.zero_()\n",
        "\n",
        "\n",
        "  if epoch%1000 == 0:\n",
        "    print(f'epoch = {epoch}, loss = {l:.8f}')\n",
        "    print(theta)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WVvZ44B1w-C",
        "outputId": "d35ba696-a4b1-4ca7-e357-d8c50169a8de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0, loss = 1.84617901\n",
            "tensor([0.4191, 0.8683, 0.5330, 0.4013], requires_grad=True)\n",
            "epoch = 1000, loss = 1.68737435\n",
            "tensor([0.3300, 0.9705, 0.6306, 0.3109], requires_grad=True)\n",
            "epoch = 2000, loss = 1.54614902\n",
            "tensor([0.2632, 1.0737, 0.7261, 0.2410], requires_grad=True)\n",
            "epoch = 3000, loss = 1.41580331\n",
            "tensor([0.2227, 1.1757, 0.8214, 0.1955], requires_grad=True)\n",
            "epoch = 4000, loss = 1.29207897\n",
            "tensor([0.2152, 1.2762, 0.9168, 0.1745], requires_grad=True)\n",
            "epoch = 5000, loss = 1.17218232\n",
            "tensor([0.2649, 1.3753, 1.0121, 0.1309], requires_grad=True)\n",
            "epoch = 6000, loss = 1.04323173\n",
            "tensor([ 0.4262,  1.4720,  1.1061, -0.0318], requires_grad=True)\n",
            "epoch = 7000, loss = 0.91775823\n",
            "tensor([ 0.5705,  1.5647,  1.1967, -0.1742], requires_grad=True)\n",
            "epoch = 8000, loss = 0.81344509\n",
            "tensor([ 0.6894,  1.6521,  1.2824, -0.2866], requires_grad=True)\n",
            "epoch = 9000, loss = 0.73887587\n",
            "tensor([ 0.7896,  1.7312,  1.3607, -0.3763], requires_grad=True)\n",
            "epoch = 10000, loss = 0.69671923\n",
            "tensor([ 0.8682,  1.7981,  1.4277, -0.4430], requires_grad=True)\n",
            "epoch = 11000, loss = 0.67994046\n",
            "tensor([ 0.9157,  1.8483,  1.4801, -0.4836], requires_grad=True)\n",
            "epoch = 12000, loss = 0.67529702\n",
            "tensor([ 0.9204,  1.8808,  1.5179, -0.4927], requires_grad=True)\n",
            "epoch = 13000, loss = 0.67302346\n",
            "tensor([ 0.8862,  1.9020,  1.5488, -0.4583], requires_grad=True)\n",
            "epoch = 14000, loss = 0.66992933\n",
            "tensor([ 0.8326,  1.9195,  1.5835, -0.3681], requires_grad=True)\n",
            "epoch = 15000, loss = 0.66574425\n",
            "tensor([ 0.7700,  1.9280,  1.6255, -0.2474], requires_grad=True)\n",
            "epoch = 16000, loss = 0.66135573\n",
            "tensor([ 0.7144,  1.9127,  1.6729, -0.1283], requires_grad=True)\n",
            "epoch = 17000, loss = 0.65729243\n",
            "tensor([ 0.6880,  1.8676,  1.7263, -0.0201], requires_grad=True)\n",
            "epoch = 18000, loss = 0.65436250\n",
            "tensor([0.7057, 1.8066, 1.7767, 0.0698], requires_grad=True)\n",
            "epoch = 19000, loss = 0.65357506\n",
            "tensor([0.7349, 1.7738, 1.7967, 0.1201], requires_grad=True)\n",
            "epoch = 20000, loss = 0.65354460\n",
            "tensor([0.7401, 1.7760, 1.7918, 0.1323], requires_grad=True)\n",
            "epoch = 21000, loss = 0.65354377\n",
            "tensor([0.7400, 1.7781, 1.7896, 0.1343], requires_grad=True)\n",
            "epoch = 22000, loss = 0.65354371\n",
            "tensor([0.7392, 1.7784, 1.7896, 0.1346], requires_grad=True)\n",
            "epoch = 23000, loss = 0.65354353\n",
            "tensor([0.7377, 1.7787, 1.7899, 0.1347], requires_grad=True)\n",
            "epoch = 24000, loss = 0.65354359\n",
            "tensor([0.7354, 1.7791, 1.7904, 0.1350], requires_grad=True)\n",
            "epoch = 25000, loss = 0.65354371\n",
            "tensor([0.7316, 1.7797, 1.7912, 0.1354], requires_grad=True)\n",
            "epoch = 26000, loss = 0.65354359\n",
            "tensor([0.7254, 1.7808, 1.7925, 0.1362], requires_grad=True)\n",
            "epoch = 27000, loss = 0.65354359\n",
            "tensor([0.7157, 1.7825, 1.7945, 0.1374], requires_grad=True)\n",
            "epoch = 28000, loss = 0.65354329\n",
            "tensor([0.7007, 1.7850, 1.7975, 0.1396], requires_grad=True)\n",
            "epoch = 29000, loss = 0.65354311\n",
            "tensor([0.6783, 1.7887, 1.8020, 0.1432], requires_grad=True)\n",
            "epoch = 30000, loss = 0.65354300\n",
            "tensor([0.6470, 1.7936, 1.8080, 0.1493], requires_grad=True)\n",
            "epoch = 31000, loss = 0.65354282\n",
            "tensor([0.6059, 1.7998, 1.8155, 0.1587], requires_grad=True)\n",
            "epoch = 32000, loss = 0.65354264\n",
            "tensor([0.5562, 1.8066, 1.8239, 0.1725], requires_grad=True)\n",
            "epoch = 33000, loss = 0.65354234\n",
            "tensor([0.4996, 1.8136, 1.8326, 0.1911], requires_grad=True)\n",
            "epoch = 34000, loss = 0.65354228\n",
            "tensor([0.4393, 1.8199, 1.8408, 0.2141], requires_grad=True)\n",
            "epoch = 35000, loss = 0.65354198\n",
            "tensor([0.3784, 1.8251, 1.8478, 0.2404], requires_grad=True)\n",
            "epoch = 36000, loss = 0.65354180\n",
            "tensor([0.3180, 1.8289, 1.8534, 0.2694], requires_grad=True)\n",
            "epoch = 37000, loss = 0.65354180\n",
            "tensor([0.2599, 1.8314, 1.8575, 0.2998], requires_grad=True)\n",
            "epoch = 38000, loss = 0.65354168\n",
            "tensor([0.2065, 1.8325, 1.8601, 0.3296], requires_grad=True)\n",
            "epoch = 39000, loss = 0.65354174\n",
            "tensor([0.1599, 1.8325, 1.8614, 0.3571], requires_grad=True)\n",
            "epoch = 40000, loss = 0.65354174\n",
            "tensor([0.1198, 1.8318, 1.8618, 0.3817], requires_grad=True)\n",
            "epoch = 41000, loss = 0.65354180\n",
            "tensor([0.0850, 1.8306, 1.8616, 0.4037], requires_grad=True)\n",
            "epoch = 42000, loss = 0.65354145\n",
            "tensor([0.0541, 1.8292, 1.8610, 0.4238], requires_grad=True)\n",
            "epoch = 43000, loss = 0.65354168\n",
            "tensor([0.0272, 1.8276, 1.8601, 0.4417], requires_grad=True)\n",
            "epoch = 44000, loss = 0.65354162\n",
            "tensor([0.0032, 1.8258, 1.8590, 0.4579], requires_grad=True)\n",
            "epoch = 45000, loss = 0.65354145\n",
            "tensor([-0.0184,  1.8241,  1.8578,  0.4727], requires_grad=True)\n",
            "epoch = 46000, loss = 0.65354151\n",
            "tensor([-0.0380,  1.8223,  1.8565,  0.4863], requires_grad=True)\n",
            "epoch = 47000, loss = 0.65354139\n",
            "tensor([-0.0557,  1.8205,  1.8552,  0.4988], requires_grad=True)\n",
            "epoch = 48000, loss = 0.65354168\n",
            "tensor([-0.0718,  1.8188,  1.8539,  0.5102], requires_grad=True)\n",
            "epoch = 49000, loss = 0.65354156\n",
            "tensor([-0.0866,  1.8171,  1.8526,  0.5207], requires_grad=True)\n",
            "epoch = 50000, loss = 0.65354151\n",
            "tensor([-0.1003,  1.8154,  1.8513,  0.5306], requires_grad=True)\n",
            "epoch = 51000, loss = 0.65354145\n",
            "tensor([-0.1132,  1.8138,  1.8500,  0.5399], requires_grad=True)\n",
            "epoch = 52000, loss = 0.65354156\n",
            "tensor([-0.1252,  1.8122,  1.8487,  0.5487], requires_grad=True)\n",
            "epoch = 53000, loss = 0.65354156\n",
            "tensor([-0.1362,  1.8106,  1.8474,  0.5568], requires_grad=True)\n",
            "epoch = 54000, loss = 0.65354145\n",
            "tensor([-0.1466,  1.8091,  1.8462,  0.5645], requires_grad=True)\n",
            "epoch = 55000, loss = 0.65354145\n",
            "tensor([-0.1563,  1.8077,  1.8450,  0.5717], requires_grad=True)\n",
            "epoch = 56000, loss = 0.65354156\n",
            "tensor([-0.1656,  1.8063,  1.8438,  0.5785], requires_grad=True)\n",
            "epoch = 57000, loss = 0.65354156\n",
            "tensor([-0.1744,  1.8049,  1.8426,  0.5851], requires_grad=True)\n",
            "epoch = 58000, loss = 0.65354145\n",
            "tensor([-0.1826,  1.8035,  1.8415,  0.5912], requires_grad=True)\n",
            "epoch = 59000, loss = 0.65354139\n",
            "tensor([-0.1903,  1.8023,  1.8404,  0.5971], requires_grad=True)\n",
            "epoch = 60000, loss = 0.65354139\n",
            "tensor([-0.1978,  1.8010,  1.8393,  0.6027], requires_grad=True)\n",
            "epoch = 61000, loss = 0.65354156\n",
            "tensor([-0.2048,  1.7997,  1.8382,  0.6081], requires_grad=True)\n",
            "epoch = 62000, loss = 0.65354145\n",
            "tensor([-0.2115,  1.7986,  1.8372,  0.6131], requires_grad=True)\n",
            "epoch = 63000, loss = 0.65354156\n",
            "tensor([-0.2179,  1.7974,  1.8362,  0.6180], requires_grad=True)\n",
            "epoch = 64000, loss = 0.65354145\n",
            "tensor([-0.2241,  1.7963,  1.8352,  0.6228], requires_grad=True)\n",
            "epoch = 65000, loss = 0.65354145\n",
            "tensor([-0.2300,  1.7952,  1.8343,  0.6273], requires_grad=True)\n",
            "epoch = 66000, loss = 0.65354151\n",
            "tensor([-0.2356,  1.7941,  1.8333,  0.6315], requires_grad=True)\n",
            "epoch = 67000, loss = 0.65354145\n",
            "tensor([-0.2410,  1.7931,  1.8324,  0.6357], requires_grad=True)\n",
            "epoch = 68000, loss = 0.65354156\n",
            "tensor([-0.2461,  1.7921,  1.8316,  0.6396], requires_grad=True)\n",
            "epoch = 69000, loss = 0.65354151\n",
            "tensor([-0.2511,  1.7911,  1.8307,  0.6435], requires_grad=True)\n",
            "epoch = 70000, loss = 0.65354156\n",
            "tensor([-0.2559,  1.7901,  1.8299,  0.6472], requires_grad=True)\n",
            "epoch = 71000, loss = 0.65354133\n",
            "tensor([-0.2605,  1.7892,  1.8290,  0.6508], requires_grad=True)\n",
            "epoch = 72000, loss = 0.65354145\n",
            "tensor([-0.2650,  1.7883,  1.8282,  0.6542], requires_grad=True)\n",
            "epoch = 73000, loss = 0.65354139\n",
            "tensor([-0.2693,  1.7874,  1.8274,  0.6576], requires_grad=True)\n",
            "epoch = 74000, loss = 0.65354133\n",
            "tensor([-0.2734,  1.7865,  1.8267,  0.6608], requires_grad=True)\n",
            "epoch = 75000, loss = 0.65354139\n",
            "tensor([-0.2774,  1.7857,  1.8259,  0.6639], requires_grad=True)\n",
            "epoch = 76000, loss = 0.65354145\n",
            "tensor([-0.2812,  1.7848,  1.8252,  0.6669], requires_grad=True)\n",
            "epoch = 77000, loss = 0.65354151\n",
            "tensor([-0.2849,  1.7841,  1.8245,  0.6697], requires_grad=True)\n",
            "epoch = 78000, loss = 0.65354156\n",
            "tensor([-0.2885,  1.7833,  1.8238,  0.6726], requires_grad=True)\n",
            "epoch = 79000, loss = 0.65354145\n",
            "tensor([-0.2920,  1.7825,  1.8231,  0.6753], requires_grad=True)\n",
            "epoch = 80000, loss = 0.65354145\n",
            "tensor([-0.2953,  1.7818,  1.8225,  0.6779], requires_grad=True)\n",
            "epoch = 81000, loss = 0.65354145\n",
            "tensor([-0.2986,  1.7811,  1.8218,  0.6804], requires_grad=True)\n",
            "epoch = 82000, loss = 0.65354151\n",
            "tensor([-0.3017,  1.7804,  1.8212,  0.6829], requires_grad=True)\n",
            "epoch = 83000, loss = 0.65354145\n",
            "tensor([-0.3047,  1.7797,  1.8206,  0.6853], requires_grad=True)\n",
            "epoch = 84000, loss = 0.65354139\n",
            "tensor([-0.3077,  1.7790,  1.8200,  0.6876], requires_grad=True)\n",
            "epoch = 85000, loss = 0.65354156\n",
            "tensor([-0.3106,  1.7783,  1.8194,  0.6899], requires_grad=True)\n",
            "epoch = 86000, loss = 0.65354156\n",
            "tensor([-0.3134,  1.7777,  1.8188,  0.6921], requires_grad=True)\n",
            "epoch = 87000, loss = 0.65354145\n",
            "tensor([-0.3161,  1.7771,  1.8182,  0.6942], requires_grad=True)\n",
            "epoch = 88000, loss = 0.65354145\n",
            "tensor([-0.3187,  1.7765,  1.8177,  0.6963], requires_grad=True)\n",
            "epoch = 89000, loss = 0.65354145\n",
            "tensor([-0.3212,  1.7758,  1.8171,  0.6983], requires_grad=True)\n",
            "epoch = 90000, loss = 0.65354133\n",
            "tensor([-0.3237,  1.7753,  1.8166,  0.7003], requires_grad=True)\n",
            "epoch = 91000, loss = 0.65354145\n",
            "tensor([-0.3262,  1.7747,  1.8161,  0.7022], requires_grad=True)\n",
            "epoch = 92000, loss = 0.65354145\n",
            "tensor([-0.3285,  1.7741,  1.8156,  0.7041], requires_grad=True)\n",
            "epoch = 93000, loss = 0.65354133\n",
            "tensor([-0.3308,  1.7736,  1.8151,  0.7059], requires_grad=True)\n",
            "epoch = 94000, loss = 0.65354133\n",
            "tensor([-0.3330,  1.7730,  1.8146,  0.7076], requires_grad=True)\n",
            "epoch = 95000, loss = 0.65354156\n",
            "tensor([-0.3351,  1.7725,  1.8141,  0.7094], requires_grad=True)\n",
            "epoch = 96000, loss = 0.65354121\n",
            "tensor([-0.3372,  1.7720,  1.8137,  0.7110], requires_grad=True)\n",
            "epoch = 97000, loss = 0.65354145\n",
            "tensor([-0.3393,  1.7715,  1.8132,  0.7127], requires_grad=True)\n",
            "epoch = 98000, loss = 0.65354145\n",
            "tensor([-0.3413,  1.7710,  1.8128,  0.7142], requires_grad=True)\n",
            "epoch = 99000, loss = 0.65354151\n",
            "tensor([-0.3432,  1.7705,  1.8123,  0.7158], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9RP9Vch2s_r",
        "outputId": "47954c38-b585-48dc-a81c-2228cbee454a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3450,  1.7701,  1.8119,  0.7172], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distances = distance_to_covs(theta,cov_mats,k)"
      ],
      "metadata": {
        "id": "OxCQvJmU3IP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNdKsBwA3YXV",
        "outputId": "d6e99ff8-f28a-4ba8-c59d-d84730716f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.6196, grad_fn=<LinalgVectorNormBackward0>),\n",
              " tensor(0.6875, grad_fn=<LinalgVectorNormBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dArg5oP37kUb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}